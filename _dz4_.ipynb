{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV4UevIGh9zO"
      },
      "source": [
        "## Обработка датасета cifar10 при помощи готовой нейронной сети ResNet50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp38QCZnEH0J",
        "outputId": "ebd97f7f-e032-4c90-d009-a9be1a3ca3a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.25.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.66.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.1.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (4.10.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2024.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.62.0)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wW1XJA8TMEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32185e6c-ba09-4aca-bc08-f4f463588db4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 5s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-cf986017975b>:44: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_generator,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 387/1562 [======>.......................] - ETA: 42:55 - loss: 52639.6641 - accuracy: 2.4225e-04"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.applications import ResNet50\n",
        "#from keras.datasets import imagenet\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.datasets import cifar10\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "import os\n",
        "\n",
        "# Установка параметров нейросети\n",
        "batch_size = 32\n",
        "num_classes = 1000\n",
        "epochs = 10\n",
        "\n",
        "# Загрузка данных cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Загрузка данных ImageNet\n",
        "# (x_train, y_train), (x_test, y_test) = imagenet.load_data()\n",
        "\n",
        "# Создание объекта ImageDataGenerator для аугментации данных и нормализация данных\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Создание генераторов для обучающей и тестовой выборок\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
        "test_generator = datagen.flow(x_test, y_test, batch_size=batch_size)\n",
        "\n",
        "# Создание предварительно обученной модели ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Создание модели для Featurization, рагружаем базовую модель в последовательную\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=len(x_train) // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=len(x_test) // batch_size)\n",
        "\n",
        "# Оценка производительности модели на тестовых данных\n",
        "score = model.evaluate_generator(test_generator, steps=len(x_test) // batch_size)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3T0qgpbVwhw"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.applications import ResNet50\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "import os\n",
        "\n",
        "# Установка параметров нейросети\n",
        "batch_size = 32\n",
        "num_classes = 1000\n",
        "epochs = 10\n",
        "\n",
        "# Загрузка данных cifar10\n",
        "# (x_train, y_train), (x_test, y_test) = imagenet.load_data() cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Создание объекта ImageDataGenerator для аугментации данных\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Создание генераторов для обучающей и тестовой выборок\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
        "test_generator = datagen.flow(x_test, y_test, batch_size=batch_size)\n",
        "\n",
        "# Создание предварительно обученной модели ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Создание модели для Featurization\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Обучение модели\n",
        "model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=len(x_train) // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=len(x_test) // batch_size)\n",
        "\n",
        "# Оценка производительности модели на тестовых данных\n",
        "score = model.evaluate_generator(test_generator, steps=len(x_test) // batch_size)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Grma58JCExFY"
      },
      "source": [
        "ТОТ же код, что и вышеописанный, с изменением количества эпох на 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TX2evybGMAE"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.applications import ResNet50V2\n",
        "from keras.applications import ResNet50\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-XgXD6EGPC2"
      },
      "outputs": [],
      "source": [
        "# Установка параметров нейросети\n",
        "batch_size = 32\n",
        "num_classes = 1000\n",
        "epochs = 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlesc_nbGUB5"
      },
      "outputs": [],
      "source": [
        "# Загрузка данных cifar10\n",
        "# (x_train, y_train), (x_test, y_test) = imagenet.load_data() cifar10\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "# Создание объекта ImageDataGenerator для аугментации данных\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXydph1oGUQZ"
      },
      "outputs": [],
      "source": [
        "# Создание генераторов для обучающей и тестовой выборок\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n",
        "test_generator = datagen.flow(x_test, y_test, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bp0NHpclGUXV"
      },
      "outputs": [],
      "source": [
        "# Создание предварительно обученной модели ResNet50\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxbfBuoGGeWV"
      },
      "outputs": [],
      "source": [
        "# Создание модели для Featurization\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e7_NoSKGed7"
      },
      "outputs": [],
      "source": [
        "model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=len(x_train) // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=len(x_test) // batch_size)\n",
        "\n",
        "# Оценка производительности модели на тестовых данных\n",
        "score = model.evaluate_generator(test_generator, steps=len(x_test) // batch_size)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dRG5gKOFEwA"
      },
      "source": [
        "ТОТ же код, что и вышеописанный, с изменением количества эпох, батчей, оптимизатора, ошибки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsXIiOnbMfLb"
      },
      "outputs": [],
      "source": [
        "# Установка параметров нейросети\n",
        "batch_size = 64\n",
        "num_classes = 1000\n",
        "epochs = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGoyiIaaGenD"
      },
      "outputs": [],
      "source": [
        "# Создание модели для Featurization\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='SGD',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fwEOhbwSpxk"
      },
      "outputs": [],
      "source": [
        "model.fit_generator(train_generator,\n",
        "                    steps_per_epoch=len(x_train) // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=len(x_test) // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ks0HnBqdMldS"
      },
      "outputs": [],
      "source": [
        "# Оценка производительности модели на тестовых данных\n",
        "score = model.evaluate_generator(test_generator, steps=len(x_test) // batch_size)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsMZ84SGuQXX"
      },
      "source": [
        "Исходя из анализа, можно сделать вывод о сложности выработки четких правил установки соотношения параметров для достижения наилучших показателей при использовании нейросетей. Также, можно сказать, что сети ResNet50 и ResNet50V2, по всей видимости, не очень подходят для обработки датасета Cifar10 (у обеих схожие результаты на низком уровне). Лучшие показатели, тем не менее, были обеспечены при использовании функции loss - sparse_categorical_crossentropy (без данной функции модель вообще ничего не могла классифицировать), optimizer - SGD и batch_size = 64. Также сеть фактически не обучалась и метрика accuracy колебалась на протяжении 25 эпох (при различных параметрах сети) от 9 до 15 % и, по сути, зависела от конкретного фрагмента датасета направляемого на тест."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}