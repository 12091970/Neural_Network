{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "http://proproprogs.ru/neural_network/kak-rekurrentnaya-neyronnaya-set-prognoziruet-simvoly\n",
        "\n",
        "\n",
        "У нас задача предсказать четвёртый символ."
      ],
      "metadata": {
        "id": "CGRvZQR1z0WS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n"
      ],
      "metadata": {
        "id": "PH_mcB21EoxE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bJQINrKnDqju"
      },
      "outputs": [],
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    text = text.replace('\\ufeff', '') # убираем первый невидимый символ\n",
        "    text = re.sub(r'[^А-я ]', '', text) # убираем все недопустимые символы"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8bKfZuZicujV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "SubXLsi5ErEN",
        "outputId": "170c40c6-b54d-4219-91d0-aa4f5f77237d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы  лучший ответ на проблемы которые возникли в понедельникДумайте позитивно и верьте в свою способность достигать отличных результатовЕсли вы смогли в понедельник подняться с постели значит вы супер герой'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyD7g4glKVps",
        "outputId": "e076bc0e-b24d-4460-a9e8-924dc4319c13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_characters = 34 #33 буквы + пробел"
      ],
      "metadata": {
        "id": "IJD76YJ4E6z0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer #для токенизации обуч.выборки"
      ],
      "metadata": {
        "id": "DgiJrgsiIK_x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)#cоздаём обуч.выборку,которую\n",
        "#надо токенизировать\n",
        "#cоздаём экз класса tokenizer\n",
        "#максимальное количество слов (символов), которое вернет Tokenizer (если\n",
        "#элементов будет больше, то останутся наиболее повторяющиеся в тексте):"
      ],
      "metadata": {
        "id": "appv1wfpIJvH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizer мы создали,теперь надо его обучить\n",
        "#И пропустим через него загруженный текст\n",
        "tokenizer.fit_on_texts(text)"
      ],
      "metadata": {
        "id": "N1yoi7pGId-n"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index) # И формируется словарь,где каждому символу поставлен в соответствие\n",
        "#свой уникальный индекс.В дальнейшем нам это пригодится, когда мы прогнозируемое значение будем\n",
        "#переводить в символ.\n",
        "\n",
        "#если на вход подаём 0,то и на выходе будет 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJmXPaQbIf-I",
        "outputId": "667ea25a-9b71-46d8-e509-8653be416c81"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'о': 2, 'т': 3, 'е': 4, 'и': 5, 'в': 6, 'н': 7, 'с': 8, 'л': 9, 'п': 10, 'ь': 11, 'ы': 12, 'р': 13, 'а': 14, 'д': 15, 'у': 16, 'к': 17, 'з': 18, 'ч': 19, 'й': 20, 'м': 21, 'г': 22, 'б': 23, 'я': 24, 'ш': 25, 'ю': 26, 'х': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Далее, преобразуем текст в набор ОНЕ-векторов:\n",
        "inp_chars = 3 # мы хотим предсказывать 4-е слово\n",
        "data = tokenizer.texts_to_matrix(text)\n",
        "#здесь символы упорядочены не по алфавиту, а в соответствии со словарем tokenizer.word_index.\n",
        "#Затем, из этой матрицы мы сформируем тензор обучающей выборки и соответствующий набор выходных значений. Для начала вычислим размер обучающего\n",
        "#множества:"
      ],
      "metadata": {
        "id": "1wWs_206JRu-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqy7uBYCJTYV",
        "outputId": "13711133-87a2-472e-9e47-79ce9885c3fe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = data.shape[0]-inp_chars # -3\n",
        "n  #размер обучающего множества"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnWQb42jKAd1",
        "outputId": "2332199a-1ecd-479c-91fe-02887f05e39d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "202"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#И, далее, сформируем входной тензор и прогнозные значения.\n"
      ],
      "metadata": {
        "id": "kvZ-iB9LKwgc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
        "Y = data[inp_chars:] #предсказание следующего символа\n"
      ],
      "metadata": {
        "id": "_nG7M5RIKsfs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X) # в Х мы сгенерировали 202 обучающих примера"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z20DCMmSK3tj",
        "outputId": "ca162f38-73f1-4031-9bcc-6176421c171c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "202"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0] #вход"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NrELysIK5fL",
        "outputId": "62333787-b858-4f56-d8db-043cebca40c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[0] #выход"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbsyrcEGK7G7",
        "outputId": "e0203e3e-cefe-4247-a251-523dd1b1987b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "lIP7yhRzLZsr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Данные для обучения готовы. Теперь создадим рекуррентную НС с помощью Keras в\n",
        "#соответствии с архитектурой рисунка выше:\n",
        "model = Sequential()\n",
        "model.add(Input((inp_chars, num_characters))) #размер входной инф - 3, 34\n",
        "model.add(SimpleRNN(500, activation='tanh')) #реккурентный слой лучше всего работает с тангенсом\n",
        "model.add(Dense(num_characters, activation='softmax')) # только одна 1 на каком-то нейроне на выходе из 34\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwyYcqGiLXPE",
        "outputId": "d2adaee8-fb61-44ab-f735-7320797c866c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_2 (SimpleRNN)    (None, 500)               267500    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 34)                17034     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284534 (1.09 MB)\n",
            "Trainable params: 284534 (1.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "history = model.fit(X, Y, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3-y2cQiMGLK",
        "outputId": "b0e8bb92-ae63-4b59-81b6-c9441721a139"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 14ms/step - loss: 3.4296 - accuracy: 0.0941\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 2.7781 - accuracy: 0.2921\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 2.3835 - accuracy: 0.2921\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 2.1431 - accuracy: 0.3465\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 1.9197 - accuracy: 0.3911\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.7531 - accuracy: 0.4505\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.6211 - accuracy: 0.5099\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.5024 - accuracy: 0.5050\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 1.3806 - accuracy: 0.5495\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.2928 - accuracy: 0.5792\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.2346 - accuracy: 0.6188\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.1802 - accuracy: 0.6337\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 1.1249 - accuracy: 0.6238\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 1.0818 - accuracy: 0.6535\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 1.0602 - accuracy: 0.6733\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 1.0134 - accuracy: 0.6832\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.9784 - accuracy: 0.7079\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.9623 - accuracy: 0.7129\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.9451 - accuracy: 0.6733\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.9311 - accuracy: 0.6881\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.9019 - accuracy: 0.7178\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8816 - accuracy: 0.7228\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8703 - accuracy: 0.7277\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.8265 - accuracy: 0.7574\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.8385 - accuracy: 0.7228\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.8033 - accuracy: 0.7475\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.7628 - accuracy: 0.7822\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.7486 - accuracy: 0.7723\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.7143 - accuracy: 0.7822\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.7378 - accuracy: 0.7624\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.7222 - accuracy: 0.7624\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7002 - accuracy: 0.7970\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6815 - accuracy: 0.8020\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6678 - accuracy: 0.7871\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6600 - accuracy: 0.7624\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6736 - accuracy: 0.7921\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6414 - accuracy: 0.7772\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6324 - accuracy: 0.7673\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6515 - accuracy: 0.7970\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6268 - accuracy: 0.8119\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6363 - accuracy: 0.7871\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6109 - accuracy: 0.8119\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6279 - accuracy: 0.7772\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6058 - accuracy: 0.7673\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5791 - accuracy: 0.8218\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6050 - accuracy: 0.8020\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6210 - accuracy: 0.7970\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6098 - accuracy: 0.8119\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6016 - accuracy: 0.7871\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5866 - accuracy: 0.7970\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5759 - accuracy: 0.8020\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5081 - accuracy: 0.8218\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5116 - accuracy: 0.8218\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5002 - accuracy: 0.8564\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5097 - accuracy: 0.8465\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4728 - accuracy: 0.8416\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5085 - accuracy: 0.8366\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4752 - accuracy: 0.8663\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5076 - accuracy: 0.8218\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5083 - accuracy: 0.7871\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4734 - accuracy: 0.8416\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4488 - accuracy: 0.8564\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4564 - accuracy: 0.8663\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4495 - accuracy: 0.8614\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4883 - accuracy: 0.8416\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4678 - accuracy: 0.8366\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4551 - accuracy: 0.8515\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4573 - accuracy: 0.8416\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4452 - accuracy: 0.8663\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4679 - accuracy: 0.8416\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.4452 - accuracy: 0.8614\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.4172 - accuracy: 0.8465\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.4148 - accuracy: 0.8564\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.4157 - accuracy: 0.8713\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.4210 - accuracy: 0.8366\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.4095 - accuracy: 0.8762\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.4208 - accuracy: 0.8515\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.4138 - accuracy: 0.8663\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.4190 - accuracy: 0.8762\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.4221 - accuracy: 0.8366\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.3925 - accuracy: 0.8564\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3746 - accuracy: 0.8762\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3664 - accuracy: 0.8960\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.3994 - accuracy: 0.8861\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.4241 - accuracy: 0.8663\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.4163 - accuracy: 0.8564\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.3617 - accuracy: 0.8812\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3661 - accuracy: 0.8960\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.3443 - accuracy: 0.8762\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3917 - accuracy: 0.8663\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3734 - accuracy: 0.8812\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.3414 - accuracy: 0.9010\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3720 - accuracy: 0.8762\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3430 - accuracy: 0.8861\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3489 - accuracy: 0.9010\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3753 - accuracy: 0.8663\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3787 - accuracy: 0.8713\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3964 - accuracy: 0.8812\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3756 - accuracy: 0.8614\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3453 - accuracy: 0.9010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Далее, объявим вспомогательную функцию, в которой будет выполняться прогноз очередного\n",
        "#символа и добавления его в конец начальной строки:\n",
        "\n",
        "def buildPhrase(inp_str, str_len = 50):\n",
        "  for i in range(str_len):\n",
        "    x = []\n",
        "    for j in range(i, i+inp_chars):\n",
        "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
        "\n",
        "    x = np.array(x)\n",
        "    inp = x.reshape(1, inp_chars, num_characters)#с помощью reshape делаем табличку 3 на 34\n",
        "\n",
        "    pred = model.predict( inp ) # предсказываем 4 символ\n",
        "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
        "\n",
        "    inp_str += d # дописываем строку\n",
        "\n",
        "  return inp_str"
      ],
      "metadata": {
        "id": "s0_LNL2pMiku"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"утренн\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-vxdO-dMijp",
        "outputId": "c44e5c4d-ad72-4a5c-a68b-2b0ba99e2e3b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "утреннрте  тлвоувчзлерьйчытеот лвнрачю тетхпввнре с туоп\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Почему такие непонятные слова - потому что 3 символа всего было задействовано.\n",
        "Строка - 50 символов."
      ],
      "metadata": {
        "id": "KiJ20hMdDbO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот текст сгенерирован посимвольно. Сеть даже пробелы расставила, а потом вышла в установившийся режим с повторяемыми фразами.\n",
        "Этот пример больше для ознакомления, чтобы показать, как кодируется текстовая информация, как формируется обучающая выборка и как строится рекуррентная сеть в Keras."
      ],
      "metadata": {
        "id": "c3dfC1lPFIBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Слова\n"
      ],
      "metadata": {
        "id": "5Lp6XvkoOYyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    texts = f.read()\n",
        "    texts = texts.replace('\\ufeff', '') # убираем первый невидимый символ"
      ],
      "metadata": {
        "id": "_-Wq8QJ2PDM2"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxWordsCount = 1000  #размер словаря, вектор из 1000 элементов(слов)\n",
        "#Каждое слово, затем, будет кодироваться one-hot вектором в соответствии с его номером в словаре:\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
        "                       lower=True, split=' ', char_level=False)\n",
        "tokenizer.fit_on_texts([texts])\n",
        "#filters - исключаемые из текста символы (по умолчанию, следующие: !-»—#$%&()*+,-./:<→>?\n",
        "#@N^-El3~\\t\\n\\r), lower = True - автоматический перевод в нижний регистр для единообразия больших и\n",
        "#малых символов,char_level=False - если False, то текст делится на слова, иначе - на символы."
      ],
      "metadata": {
        "id": "revghpcNPQSd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizer обучили и на выходе-словарь\n",
        "dist = list(tokenizer.word_counts.items())\n",
        "print(dist[:10])\n",
        "#Здесь отображаются кортежи со словом и его частотой встречаемости в тексте."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPga89Z4PVFe",
        "outputId": "3a5ab760-5cc2-4744-f924-532db76cded4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('вы', 3), ('лучший', 1), ('ответ', 1), ('на', 1), ('проблемы', 1), ('которые', 1), ('возникли', 1), ('в', 3), ('понедельник', 2), ('думайте', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = tokenizer.texts_to_sequences([texts])\n",
        "#Далее, мы преобразуем текст в последовательность чисел в соответствии с полученным словарем.\n",
        "#Для этого используется специальный метод класса Tokenizer."
      ],
      "metadata": {
        "id": "7mpCwwYQP5hV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data #На выходе получим массив чисел объекта numpy:\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPDrhzF4P7Lk",
        "outputId": "ff005037-afa3-4500-c65d-c91cee9deafc"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  7,\n",
              "  8,\n",
              "  9,\n",
              "  2,\n",
              "  3,\n",
              "  10,\n",
              "  11,\n",
              "  12,\n",
              "  13,\n",
              "  2,\n",
              "  14,\n",
              "  15,\n",
              "  16,\n",
              "  17,\n",
              "  18,\n",
              "  19,\n",
              "  1,\n",
              "  20,\n",
              "  2,\n",
              "  3,\n",
              "  21,\n",
              "  22,\n",
              "  23,\n",
              "  24,\n",
              "  1,\n",
              "  25,\n",
              "  26]]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA6DuYkoQS8N",
        "outputId": "486abb6c-d404-4e8a-ee96-4e4466bd4d0f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Осталось закодировать числа массива data в one-hot векторы. Для этого мы воспользуемся методом\n",
        "# to_categorical пакета Keras:\n",
        "res = keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "print( res.shape )\n",
        "#каждое слово заменили вектором на 1000 чисел, но единица там будет одна"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILtfEKKIQH2d",
        "outputId": "a02c85c5-12a0-4682-ef0a-ac232a8fdbf5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words = 3 # ПРИ ОБУЧЕНИИ БУДЕМ УЧИТЫВАТЬ 3 ПРЕДЫДУЩИХ СЛОВА\n",
        "n = res.shape[0]-inp_words"
      ],
      "metadata": {
        "id": "pVSmTo2qQyer"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "Y = res[inp_words:]"
      ],
      "metadata": {
        "id": "_ljnZUqXQ3Zz"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_words, maxWordsCount)))\n",
        "model.add(SimpleRNN(128, activation='tanh'))\n",
        "model.add(Dense(maxWordsCount, activation='softmax')) #ТОЛЬКО СЕЙЧАС НА ВЫХОДЕ 1000 нейронов(maxWordsCount)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc8dLHkSQ9Nr",
        "outputId": "41d2cb4d-d051-4977-bb26-f2367c0fc071"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_5 (SimpleRNN)    (None, 128)               144512    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1000)              129000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273512 (1.04 MB)\n",
            "Trainable params: 273512 (1.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, batch_size=32, epochs=19)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av36xtecRA8L",
        "outputId": "d94505f5-289f-4a71-c7cc-882df8ca8770"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/19\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.9082 - accuracy: 0.0000e+00\n",
            "Epoch 2/19\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 6.8824 - accuracy: 0.0000e+00\n",
            "Epoch 3/19\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.8564 - accuracy: 0.0000e+00\n",
            "Epoch 4/19\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 6.8300 - accuracy: 0.1786\n",
            "Epoch 5/19\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.8028 - accuracy: 0.4286\n",
            "Epoch 6/19\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.7747 - accuracy: 0.6429\n",
            "Epoch 7/19\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.7453 - accuracy: 0.8214\n",
            "Epoch 8/19\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.7144 - accuracy: 0.8929\n",
            "Epoch 9/19\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 6.6815 - accuracy: 0.8929\n",
            "Epoch 10/19\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.6462 - accuracy: 0.8929\n",
            "Epoch 11/19\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.6081 - accuracy: 0.9286\n",
            "Epoch 12/19\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.5666 - accuracy: 0.9286\n",
            "Epoch 13/19\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.5211 - accuracy: 0.9643\n",
            "Epoch 14/19\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.4710 - accuracy: 0.9643\n",
            "Epoch 15/19\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.4153 - accuracy: 1.0000\n",
            "Epoch 16/19\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 6.3530 - accuracy: 1.0000\n",
            "Epoch 17/19\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 6.2831 - accuracy: 1.0000\n",
            "Epoch 18/19\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 6.2042 - accuracy: 1.0000\n",
            "Epoch 19/19\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.1148 - accuracy: 0.9643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iqy_4ucCUAbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Запишем функцию для формирования текста из спрогнозированных слов:\n",
        "\n",
        "def buildPhrase(texts, str_len = 20):\n",
        "  res = texts\n",
        "  data = tokenizer.texts_to_sequences([texts])[0]\n",
        "  for i in range(str_len):\n",
        "    x = keras.utils.to_categorical(data[i: i+inp_words], num_classes=maxWordsCount) # преобразуем в One-Hot-encoding\n",
        "    inp = x.reshape(1, inp_words, maxWordsCount)\n",
        "\n",
        "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    indx = pred.argmax(axis=1)[0]\n",
        "    data.append(indx)\n",
        "\n",
        "    res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
        "\n",
        "  return res\n"
      ],
      "metadata": {
        "id": "ct7fLPkCUKfN"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = tokenizer. texts_to_sequences ([texts])[0]"
      ],
      "metadata": {
        "id": "zaExO8xeYakL"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RJdNou2Yjlx",
        "outputId": "16f5b232-a194-412b-a7d6-d86c23e03c86"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 2,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 1,\n",
              " 20,\n",
              " 2,\n",
              " 3,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 1,\n",
              " 25,\n",
              " 26]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1):\n",
        "    x = keras.utils.to_categorical(data[i: i+inp_words], num_classes=maxWordsCount)"
      ],
      "metadata": {
        "id": "yrBbGq92UeSP"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = x.reshape(1, inp_words, maxWordsCount)"
      ],
      "metadata": {
        "id": "dzSLOq0rY2Z6"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4sPNN7HZIYK",
        "outputId": "00cd0d41-6e95-419e-dc8a-ad434d763a6b"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 1., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x) #x-это категоризация первых 3-х слов"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17IjFNOxZjXd",
        "outputId": "b140810b-b8b0-4df0-ebf5-4fc276d10732"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#И вызовем ее с тремя первыми словами:\n",
        "res = buildPhrase(\"позитив добавляет годы\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "v2L7ReIFRUuz",
        "outputId": "5739a875-6edb-475e-c716-052f3714ab1f"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 0 into shape (1,3,1000)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-131-af55faac1ff1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#И вызовем ее с тремя первыми словами:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildPhrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"позитив добавляет годы\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-9d3b13e36536>\u001b[0m in \u001b[0;36mbuildPhrase\u001b[0;34m(texts, str_len)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minp_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxWordsCount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# преобразуем в One-Hot-encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxWordsCount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m# предсказываем OHE четвертого символа\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (1,3,1000)"
          ]
        }
      ]
    }
  ]
}